# -*- coding: utf-8 -*-
"""seo-analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wn1R7NYtOcHJzcIf2X-m3NuSybu86_jC
"""

pip install requests beautifulsoup4 lxml

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Fetch page
def fetch_page(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    return BeautifulSoup(response.text, 'lxml')

# Meta tags
def analyze_meta(soup):
    title = soup.title.string if soup.title else 'No title'
    description = ''
    keywords = ''
    for tag in soup.find_all('meta'):
        if tag.get('name') == 'description':
            description = tag.get('content', '')
        if tag.get('name') == 'keywords':
            keywords = tag.get('content', '')
    return {'title': title, 'description': description, 'keywords': keywords}

# Headings
def analyze_headings(soup):
    headings = {}
    for level in range(1, 7):
        headings[f'h{level}'] = [h.get_text(strip=True) for h in soup.find_all(f'h{level}')]
    return headings

# Images
def analyze_images(soup):
    images = soup.find_all('img')
    missing_alt = [img['src'] for img in images if not img.get('alt')]
    return {'total_images': len(images), 'missing_alt': missing_alt}

# Robots.txt and sitemap.xml
def check_robots_and_sitemap(base_url):
    robots_url = urljoin(base_url, '/robots.txt')
    sitemap_url = urljoin(base_url, '/sitemap.xml')
    robots = requests.get(robots_url).status_code == 200
    sitemap = requests.get(sitemap_url).status_code == 200
    return {'robots.txt': robots, 'sitemap.xml': sitemap}

# Master analyzer
def seo_analyzer(url):
    soup = fetch_page(url)
    result = {
        'Meta Tags': analyze_meta(soup),
        'Headings': analyze_headings(soup),
        'Images': analyze_images(soup),
        'Robots & Sitemap': check_robots_and_sitemap(url)
    }
    return result

# Run it
if __name__ == '__main__':
    url = input("Enter a website URL (e.g. https://example.com): ").strip()
    report = seo_analyzer(url)
    for section, data in report.items():
        print(f'\n{section}:\n{"-"*30}')
        print(data)